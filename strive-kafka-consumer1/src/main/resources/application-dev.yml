# 日志地址
logPath: /Users/shizijie/spring-boot-log/beta/strive

logging:
  file: ${logPath}/${spring.application.name}.log
  level:
    org.springframework: info

server:
  undertow:
    # 设置IO线程数, 它主要执行非阻塞的任务,它们会负责多个连接, 默认设置每个CPU核心一个线程
    io-threads: 2
    # 阻塞任务线程池, 当执行类似servlet请求阻塞操作, undertow会从这个线程池中取得线程,它的值设置取决于系统的负载
    worker-threads: 20
    # 每块buffer的空间大小,越小的空间被利用越充分，不要设置太大，以免影响其他应用，合适即可
    buffer-size: 1024
    # 是否分配的直接内存(NIO直接分配的堆外内存)
    direct-buffers: true
    accesslog:
      enabled: true
      dir: ${logPath}
      #pattern: '%t %a %A %{i,X-Forwarded-For} %p %r %s %b "%{i,Referer}" "%{i,User-Agent}" (%D ms)'
      pattern: '[%{time,yyyy-MM-dd HH:mm:ss.S z}] %m %U "%q" %s %D %b %{i,X-B3-TraceId},%{i,X-B3-SpanId} %{i,X-Real-IP} %{i,Referer} "%{i,User-Agent}" %{i,Platform} %l %u %I %v %a'
      prefix: undertow-${spring.application.name}.
spring:
  datasource:
    # 使用阿里的Druid连接池
    type: com.alibaba.druid.pool.DruidDataSource
    druid:
      driver-class-name: com.mysql.jdbc.Driver
      url: jdbc:mysql://127.0.0.1:33306/beta?characterEncoding=utf8&useSSL=false
      username: root
      password: 123456
      # 连接池的配置信息
      name: ${spring.application.name}
      # 初始化大小，最小，最大
      initial-size: 5
      min-idle: 5
      maxActive: 20
      # 配置获取连接等待超时的时间
      maxWait: 60000
      # 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒
      timeBetweenEvictionRunsMillis: 60000
      # 配置一个连接在池中最小生存的时间，单位是毫秒
      minEvictableIdleTimeMillis: 300000
      validationQuery: SELECT 1
      testWhileIdle: true
      testOnBorrow: false
      testOnReturn: false
      # 打开PSCache，并且指定每个连接上PSCache的大小
      poolPreparedStatements: true
      maxPoolPreparedStatementPerConnectionSize: 20
      # 配置监控统计拦截的filters，去掉后监控界面sql无法统计，'wall'用于防火墙
      filters: stat,wall #,log4j
      # 通过connectProperties属性来打开mergeSql功能；慢SQL记录
      connectionProperties: druid.stat.mergeSql\=true;druid.stat.slowSqlMillis\=5000
      # 配置DruidStatFilter
      web-stat-filter:
        enabled: true
        url-pattern: "/*"
        exclusions: "*.js,*.gif,*.jpg,*.bmp,*.png,*.css,*.ico,/druid/*"
      # 配置DruidStatViewServlet
      stat-view-servlet:
        url-pattern: "/druid/*"
        # IP白名单(没有配置或者为空，则允许所有访问)
        allow: 127.0.0.1,192.168.163.1
        # IP黑名单 (存在共同时，deny优先于allow)
        deny: 192.168.1.73
        #  禁用HTML页面上的“Reset All”功能
        reset-enable: false
        # 登录名
        login-username: admin
        # 登录密码
        login-password: admin


  #redis
  redis:
    database: 0
    host: 127.0.0.1
    password: foobared
    port: 36379
    lettuce:
      pool:
        # 连接池最大连接数（使用负值表示没有限制）
        max-active: 16
        # 连接池最大阻塞等待时间（使用负值表示没有限制）
        max-wait: 10000
        # 连接池中的最大空闲连接
        max-idle: 8
        # 连接池中的最小空闲连接
        min-idle: 5
      # 关闭超时时间
      shutdown-timeout: 100

  kafka:
    bootstrap-servers: localhost:9092,localhost:9093,localhost:9094
#    producer:
#      retries: 0
#      batch-size: 16384
#      buffer-memory: 33554432
#      key-serializer: org.apache.kafka.common.serialization.StringSerializer
#      value-serializer: org.apache.kafka.common.serialization.StringSerializer
    consumer:
      group-id: testconsumer1
      enable-auto-commit: true
      auto-commit-interval: 100
      key-serializer: org.apache.kafka.common.serialization.StringDeserializer
      value-serializer: org.apache.kafka.common.serialization.StringDeserializer
      bootstrap-servers: localhost:9092,localhost:9093,localhost:9094
      auto-offset-reset: earliest